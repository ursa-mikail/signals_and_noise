# Noise Determination For Data Privacy

To choose between Gaussian and Laplacian noise and determine if the Signal-to-Noise Ratio (SNR) is good enough for data privacy, you need to understand the goals of your privacy model, the expected sensitivity of the data, and the requirements of your application (e.g., analytics, ML, publication). 

## ðŸ” 1. Choosing Between Gaussian and Laplacian Noise

| Criteria                    | **Gaussian Noise**                                       | **Laplacian Noise**                         |
| --------------------------- | -------------------------------------------------------- | ------------------------------------------- |
| **Privacy Model**           | (Îµ, Î´)-**Differential Privacy**                          | Îµ-**Differential Privacy**                  |
| **Use Case**                | When Î´ (small probability of failure) is acceptable      | When strict Îµ-DP is required                |
| **Distribution Shape**      | Bell curve, smoother tail                                | Sharp peak, heavier tail                    |
| **Sensitivity Handling**    | Works well for **group privacy**, advanced composition   | Better for single query, simple composition |
| **Mathematical Simplicity** | Requires **more complex analysis**                       | Simple closed-form mechanism                |
| **Common Applications**     | Machine learning, federated learning, correlated queries | Queryable databases, one-shot stats release |

> Rule of Thumb:
> Use Laplacian for simpler, strict privacy settings (like static query releases).
> Use Gaussian for more complex, composed or iterative systems (e.g., training ML models).

## ðŸ“ 2. How to Choose the Privacy Parameters (Îµ, Î´) or Sensitivity
ðŸ”¹ Sensitivity (Î”f)
This is the maximum change in the output if a single individual's data changes.

- For Laplace noise:
Noise ~ Lap(Î”f / Îµ)

- For Gaussian noise:
Noise ~ N(0, ÏƒÂ²), where
Ïƒ â‰¥ âˆš(2 * log(1.25/Î´)) * Î”f / Îµ

> Î”f depends on the query.

> Count queries: Î”f = 1

> Sum queries: Î”f = max possible value

> Mean: Î”f = (max - min) / n


## ðŸŽ¯ 3. Evaluating Signal-to-Noise Ratio (SNR) for Privacy
SNR Formula:
$$\ \frac{Var(signal)}{Var(noise)} \$$

> High SNR â†’ Useful data, but weaker privacy.
> Low SNR â†’ Better privacy, but less utility.

| SNR Range | Interpretation                                      |
| --------- | --------------------------------------------------- |
| **> 10**  | High utility, but may **leak privacy**              |
| **1â€“10**  | **Balanced trade-off**: decent privacy, usable data |
| **< 1**   | Strong privacy, **poor utility**                    |

> In privacy-first systems, aim for SNR < 1 to 3, depending on risk tolerance.

## âš–ï¸ 4. Practical Selection Strategy

1. Determine the privacy budget (Îµ, Î´):
- Small Îµ (e.g., 0.1â€“1): Strong privacy
- Larger Îµ (e.g., 2â€“5): Weaker, but more utility
- Î´ â‰ª 1/n for Gaussian noise, where n = dataset size

2. Calculate the sensitivity (Î”f) of your function.

3. Choose noise mechanism:
- Use Laplace if Î´ = 0 (strict DP).
- Use Gaussian if you're doing multiple queries/compositions or using tools like PATE/Federated Learning.

4. Simulate or analyze SNR:
- Generate sample outputs with and without noise.
- Measure how distinguishable the outputs are.

<hr>

ðŸ§ª Example
Suppose you release the average income of a dataset:
- Max income = $500k, Min = $0, n = 1000
- Sensitivity = (500,000 - 0) / 1000 = 500
- Îµ = 1 (reasonable privacy)

- Laplacian Noise:
	- Scale = 500 / 1 = 500
	- Var(noise) = 2 Ã— (500)Â² = 500,000

Assume signal variance = 1,000,000
â†’ SNR = 1,000,000 / 500,000 = 2 â†’ Acceptable


âœ… Run privacy-utility simulations before deployment.

âœ… If using ML, consider privacy accounting tools like:
- TensorFlow Privacy
- Opacus (PyTorch)

âœ… Use RÃ©nyi Differential Privacy (RDP) if doing repeated queries to track Îµ budget better.

## ðŸ“Š Signal & Noise Variance
Example: 
- Signal variance (original data): ~219 million
- Laplace noise variance: ~529 thousand
- Gaussian noise variance: ~5.4 million

## ðŸ”‰ Signal-to-Noise Ratios (SNR)
- SNR (Laplace noise): ~414 â†’ Very high utility, low privacy risk
- SNR (Gaussian noise): ~40.6 â†’ Still good utility, but better privacy

## ðŸŽ¯ Interpretation
- An SNR > 10 generally implies the signal is still easily distinguishable from the noise.
- If aiming for stronger privacy, and for SNR values below 10, preferably 1â€“3 depending on the threat model.
- The current noise levels are quite mild for both mechanisms, suggesting you could:
	- Increase noise (reduce Îµ or increase Î´ for Gaussian),
	- Or check if this level of privacy is adequate for the needs.

![noise_additions_and_SnR](noise_additions_and_SnR.png)

## Tuneable Îµ, Î´, or sensitivity to see how the SNR and distributions change

### ðŸ”µ Laplace SNR (Îµ vs Sensitivity)
- Higher Îµ (weaker privacy) â†’ Higher SNR (better utility).
- Lower sensitivity â†’ also improves SNR significantly.
- For example, at Îµ = 5 and sensitivity = 100, SNR > 2000 â†’ near-original utility.

### ðŸ”´ Gaussian SNR (Îµ vs Sensitivity, fixed Î´ = 1e-5)
- SNR is generally lower than Laplace for the same Îµ and sensitivity â€” indicating stronger privacy.
- Still, increasing Îµ or reducing sensitivity improves SNR.
- For Îµ = 5 and sensitivity = 100, SNR is ~180 â€” strong utility, moderate privacy.

![tune_noise_SnR](tune_noise_SnR.png)

### ðŸ“Œ Summary of Tuning Effects:
| Parameter       | Increase | Effect                       |
| --------------- | -------- | ---------------------------- |
| **Îµ (epsilon)** | â†‘        | â†“ Privacy, â†‘ SNR (â†‘ utility) |
| **Î´ (delta)**   | â†‘        | â†“ Privacy for Gaussian only  |
| **Sensitivity** | â†‘        | â†“ SNR (â†‘ noise), â†‘ privacy   |

# Interactive-style 3D surface plots
ðŸ”· Left: Laplace SNR Surface
High epsilon (towards the front right) leads to very high SNR, meaning weaker privacy.

High sensitivity (toward the back) reduces SNR â€” more noise for the same Îµ.

ðŸ”¶ Right: Gaussian SNR Surface
More curved and sensitive to both Îµ and sensitivity.

Because of the Î´ component, Gaussian noise grows faster with sensitivity than Laplace.

âœ… Takeaways
Laplace is more sensitive to Îµ and less to Î´ (which it doesnâ€™t even use).

Gaussian requires careful Î´ tuning and is more useful when you need composability or approximate DP.

Use these plots to decide the optimal Îµ/sensitivity pair to balance privacy budget and data utility.

![noise_3d_surface_plots](noise_3d_surface_plots.png)

![noise_interactive_00_00](noise_interactive_00_00.png)

![noise_interactive_00_01](noise_interactive_00_01.png)

![noise_interactive_00_02](noise_interactive_00_02.png)




